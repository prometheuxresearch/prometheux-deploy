appName prometheux
## [OPTIONS] local[*], local[Number_of_cores], 
## spark://HOST:PORT, yarn 
spark.master local[*]
## max memory for driver
spark.driver.memory 4g
## max memory per executor
spark.executor.memory 4g
## [OPTIONS] cluster, client
spark.submit.deployMode client
## number of executor per instance of each worker
spark.executor.instances 1
## number of cores on each executor
spark.executor.cores 4
## allocates dynamically instances and cores
spark.dynamicAllocation.enabled false
## autotune the shuffle partition number
spark.sql.adaptive.enabled true
## the number of partitions to use when shuffling data for joins or aggregations
## if run in local[*] mode set this number as the number of your machine's core
## if run in yarn mode set this number as the number of machine * number of cores of each machine
spark.sql.shuffle.partitions 4
## yarn properties for distributed reasoning
## hadoop FS dir
spark.hadoop.defaultFS hdfs://localhost:9000
## Staging directory used for storing checkpoint
spark.yarn.stagingDir hdfs://localhost:9000/user/
## dir where jars for spark are
## spark.yarn.jars hdfs://localhost:9000/user/hadoop/jars/*
## hostname of resource manager
spark.hadoop.yarn.resourcemanager.hostname localhost
## Ip address and port of resource manager
spark.hadoop.yarn.resourcemanager.address localhost:8032
## Ip address and port of resource manager scheduler
spark.hadoop.yarn.resourcemanager.scheduler.address localhost:8030
## spark serializer
spark.serializer org.apache.spark.serializer.KryoSerializer
## jars to distribute that include lambda functions
## spark.jars thirdparty/distributed-add-on/distributed-aggregations-add-on-1.13.5.jar
## directory to use for scratch space
spark.local.dir tmp
## Whether to compress RDD checkpoints
spark.checkpoint.compress true
## Whether to compress before shuffling
spark.shuffle.compress true
## Set this property to -1 to use SortMergeJoin instead of Broadcast Hash Join
## spark.sql.autoBroadcastJoinThreshold -1
spark.driver.port 6066