property.filename=Default
property.version=0.1
testKey=testValue
postgresql.url= jdbc:postgresql://postgres:5432/postgres
postgresql.username=postgres
postgresql.password=postgres
postgresql.platform=postgresql
postgresql.driverClassName=org.postgresql.Driver
postgresql.fetchSize=20000
postgresql.batchSize=20000
sqlite.url=jdbc:sqlite:sqlite/testdb.db
sqlite.platform=sqlite
repository.path=disk
decimal_digits=3
neo4j.platform=neo4j
neo4j.url=bolt://localhost:7687
neo4j.username=neo4j
neo4j.password=neo4j2
neo4j.database=neo4j
# none,basic,kerberos,custom,bearer
neo4j.authentication.type=basic
neo4j.relationshipNodesMap=false
neo4j.partitions=1
# properties when the chase wants to be stored on neo4j
neo4j.chase.url=bolt://localhost:7687
neo4j.chase.username=neo4j
neo4j.chase.password=neo4j2
neo4j.chase.database=neo4j
neo4j.chase.authenticationType=basic
neo4j.writeBatchSize=20000
mariadb.platform=mariadb
mariadb.url=jdbc:mysql://localhost:3306
mariadb.username=maria
mariadb.password=maria
mariadb.fetchSize=20000
mariadb.batchSize=20000
state.platform=state
csv.platform=csv
csv.nullGenerationMode=UNIQUE_NULLS
csv.withHeader=false

## sqlite cache
sqliteCache.url=jdbc:sqlite:sqlite/sqliteDb.db
cacheMemorySizeBytes=1G
cachePageSize = 200000
percentageSizeSwapOut=15
## whether to create unique nulls or not 
## UNIQUE_NULLS, SAME_NULLS
nullGenerationMode=UNIQUE_NULLS
## whether to unify the output in one partition supported only with local[*]  
coalescePartitions=false
forNeo4jBulkImport=false
# compression codec to use when saving to file
## availables are false, uncompressed, snappy, gzip, lzo, brotli, lz4, and zstd
## for parquet, default is snappy
compression=none
## full path to spark configurations file
sparkConfFile=spark-defaults.conf
## storage level for dataset persistence
persistanceStorageLevel=memoryOnly
## diverse optimization for the physical plan
## default, snaJoin, sna, noTermination
optimizationStrategy=default
# HashToMin, GraphStar
egdDistributedConnectedComponentsAlgo=HashToMin
## for livy rest service set this property to restService=livy
restService=off
## strategies to break the lineage in iterative computations
## localCheckpoint, checkpoint, recreate
breakLineageStrategy=localCheckpoint
## dir to store local checkpoints for breaking lineage in iterative computations
checkpointDir=localCheckpoints
## full path to spark rapids configurations file
sparkRapidsConfFile=spark-rapids.conf
## whether to select the preferred compute accelerator: cpu or gpu
computeAcceleratorPreference=cpu